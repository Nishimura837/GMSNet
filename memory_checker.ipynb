{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMSNet_kataoka_nishimura_fixing test.ipynb を元に、使用感を高めるために改良する\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testを実行するためのコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シフト切り捨てをやめてみる\n",
    "# トレーニング完了後のトレーニングメッシュを表示してみる\n",
    "# 各epochの終了時にメッシュを可視化してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphNorm, LayerNorm\n",
    "import torch_geometric.transforms as T\n",
    "from torch.nn import Linear, InstanceNorm2d, InstanceNorm1d, Conv1d, ReLU, Tanh\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.transforms import FaceToEdge\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from itertools import combinations\n",
    "import vtk\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "# 計算を軽くするためのライブラリ\n",
    "from torch.cuda import empty_cache\n",
    "import gc               # メモリリークを防ぐ\n",
    "\n",
    "from torch import nn\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import datetime\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"/mnt/Test_Data/\"\n",
    "fig_save_path = \"/mnt/Optimized_mesh_Folder/\"\n",
    "vtk_save_path = \"/mnt/optimized_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_epoch = 1\n",
    "num_trial = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, num_files):\n",
    "        None\n",
    "\n",
    "class Mesh(Dataset):\n",
    "    def __init__(self):\n",
    "        self.coordinates = None\n",
    "        self.faces = None\n",
    "\n",
    "class Polygon(Dataset):\n",
    "    def __init__(self, num_node, num_face):\n",
    "        self.parent_meshID = None\n",
    "        self.coordinates = torch.zeros(num_node, 2)\n",
    "        self.faces = torch.zeros(num_face, 3)\n",
    "        self.edges = None\n",
    "        self.d = None\n",
    "        self.Cx = None\n",
    "        self.Cy = None\n",
    "        self.x_min = None\n",
    "        self.y_min = None\n",
    "\n",
    "class PolygonID(Dataset):\n",
    "    def __init__(self, nodeID):\n",
    "        self.nodeID = nodeID\n",
    "\n",
    "class Polygon_data(Dataset):\n",
    "    def __init__(self, polygonID, meshID, nodeID):\n",
    "        self.polygonID = polygonID\n",
    "        self.meshID = meshID\n",
    "        self.nodeID = nodeID\n",
    "\n",
    "class Minibatch(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.edge_index = None\n",
    "        self.batch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesh_polygonID_data(vtk_file_path, polygonID_list, poly_count, polygon_dict, mesh_index):\n",
    "    reader = vtk.vtkDataSetReader()\n",
    "    reader.SetFileName(vtk_file_path)\n",
    "    reader.Update()\n",
    "\n",
    "    data = reader.GetOutput()\n",
    "    \n",
    "    mesh = Mesh()\n",
    "    # 座標情報を取得\n",
    "    points = data.GetPoints()\n",
    "    num_points = points.GetNumberOfPoints()\n",
    "    coordinates = torch.zeros(num_points, 3)\n",
    "    for i in range(num_points):\n",
    "        coordinates[i] = torch.tensor(points.GetPoint(i))\n",
    "\n",
    "    mesh.coordinates = coordinates[:, :2]                        # mesh.coordinates を定義\n",
    "\n",
    "    # 面情報を取得\n",
    "    polys = data.GetPolys()\n",
    "    num_polys = polys.GetNumberOfCells()\n",
    "    mesh.faces = torch.zeros(num_polys, 3, dtype=int)           # mesh.faces を定義\n",
    "\n",
    "    # 各三角形の情報を取得\n",
    "    polys.InitTraversal()\n",
    "    for i in range(num_polys):\n",
    "        cell = vtk.vtkIdList()\n",
    "        if polys.GetNextCell(cell) == 0:\n",
    "            break\n",
    "        mesh.faces[i] = torch.tensor([cell.GetId(0), cell.GetId(1), cell.GetId(2)])\n",
    "        \n",
    "# ------------ mesh のデータを取得完了 -------------------------\n",
    "\n",
    "\n",
    "    # 各セルの各辺の隣接セル数を調べる\n",
    "    edge_neighbors = {}\n",
    "    num_cells = data.GetNumberOfCells()\n",
    "    for cell_index in range(num_cells):\n",
    "        cell = data.GetCell(cell_index)\n",
    "        num_edges = cell.GetNumberOfEdges()\n",
    "\n",
    "        for edge_index in range(num_edges):\n",
    "            edge = cell.GetEdge(edge_index)\n",
    "            edge_points = edge.GetPointIds()\n",
    "\n",
    "            # 辺を構成する点のインデックスを取得\n",
    "            point1_id = edge_points.GetId(0)\n",
    "            point2_id = edge_points.GetId(1)\n",
    "\n",
    "            # 辺を構成する点のインデックスを昇順にソート\n",
    "            edge_key = (min(point1_id, point2_id), max(point1_id, point2_id))\n",
    "\n",
    "            # 辺の隣接セル数をカウント\n",
    "            if edge_key in edge_neighbors:\n",
    "                edge_neighbors[edge_key] += 1\n",
    "            else:\n",
    "                edge_neighbors[edge_key] = 1 \n",
    "\n",
    "    boundary_edges = []\n",
    "    # 境界上の辺を特定\n",
    "    for edge_key, num_neighbors in edge_neighbors.items():\n",
    "        if num_neighbors == 1:\n",
    "            boundary_edges.append(edge_key)\n",
    "\n",
    "    # 境界上の辺を構成する頂点の番号を取得\n",
    "    boundary_points = set()     # 集合を表すデータ型、順番を持たず、重複した要素は取り除かれる\n",
    "# ---------------- 自由点かどうかの判定完了 ------------------------\n",
    "    \n",
    "\n",
    "    for edge_key in boundary_edges:\n",
    "        boundary_points.add(edge_key[0])\n",
    "        boundary_points.add(edge_key[1])\n",
    "    \n",
    "    \n",
    "    for pointId in range(num_points):       # pointId:自由点の頂点番号\n",
    "        if pointId in boundary_points:\n",
    "            continue\n",
    "        else:\n",
    "            poly_count += 1\n",
    "            # print(\"pointId:\", pointId)\n",
    "        mask = (mesh.faces == pointId)\n",
    "        if mask.any():\n",
    "            count = torch.sum(mask).item()\n",
    "        num_node = count + 1\n",
    "        num_face = count\n",
    "        polygon_number = poly_count - 1 \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        polygon_i = f\"polygon_{polygon_number}\"\n",
    "        # print(polygon_i)\n",
    "        polygon_i = Polygon(num_node, num_face)\n",
    "        \n",
    "        element_to_check = pointId\n",
    "        polygon_i.face = mesh.faces[(mesh.faces == element_to_check).any(dim=1)]\n",
    "        # print(polygon_i.face)\n",
    "\n",
    "        polygon_i.nodeId = set()\n",
    "        for i in range(len(polygon_i.face)):\n",
    "            polygon_i.nodeId.add(polygon_i.face[i, 0].item())\n",
    "            polygon_i.nodeId.add(polygon_i.face[i, 1].item())\n",
    "            polygon_i.nodeId.add(polygon_i.face[i, 2].item())\n",
    "        sorted_nodeId = sorted(polygon_i.nodeId)\n",
    "        polygon_i.nodeID = torch.tensor(list(sorted_nodeId))\n",
    "        \n",
    "        point_id_index = (polygon_i.nodeID == pointId).nonzero().item()\n",
    "\n",
    "        value_to_move = polygon_i.nodeID[point_id_index]\n",
    "        polygon_i.nodeID = torch.cat((value_to_move.unsqueeze(0), polygon_i.nodeID[polygon_i.nodeID != pointId]))\n",
    "        # print(polygon_i.nodeID)\n",
    "        setattr(polygon_i, \"parent_meshID\", mesh)\n",
    "        polygonID_list.append(f\"polygon_{polygon_number}\")\n",
    "\n",
    "        keyword = f\"polygon_{polygon_number}\"\n",
    "        valiables = (f\"mesh_{mesh_index}\", polygon_i.nodeID)\n",
    "        polygon_dict[keyword] = valiables\n",
    "\n",
    "    # --------- polygon.nodeID の取得完了 -------------\n",
    "    return mesh, polygonID_list, poly_count, polygon_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesh_polygon_dataset(vtk_files):\n",
    "    num_vtk_files = len(vtk_files)\n",
    "    polygonID_list = []\n",
    "    mesh_data_list = []\n",
    "    poly_count = 0\n",
    "    polygon_dict = {}\n",
    "    # ファイルに順にアクセスする\n",
    "    for i in range(num_vtk_files):\n",
    "        # print(\"File Name:\", vtk_files[i])\n",
    "        mesh, polygonID_list, poly_count, polygon_dict = create_mesh_polygonID_data(vtk_files[i], polygonID_list, poly_count, polygon_dict, i)\n",
    "        mesh_data_list.append(mesh)\n",
    "    return mesh_data_list, polygonID_list, polygon_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下、i はpolygon番号で座標と面情報を取得することができる\n",
    "face_to_edge = T.FaceToEdge(remove_faces=False)\n",
    "def data_getter(polygonID, num_mesh_data_list, mesh_data_list, polygon_data_list):\n",
    "    \n",
    "    polygon_meshID = int(polygon_data_list[polygonID].meshID.split(\"_\")[-1])\n",
    "    # print(\"polygon_meshID:\", polygon_meshID)\n",
    "    mesh = mesh_data_list[polygon_meshID]\n",
    "    \n",
    "    num_node = len(polygon_data_list[polygonID].nodeID)\n",
    "    num_face = num_node - 1 \n",
    "    polygon_i = Polygon(num_node, num_face)\n",
    "\n",
    "    # print(polygon_data_list[polygonID].nodeID)      # polygon に属する頂点の番号\n",
    "\n",
    "    polygon_i.coordinates = mesh.coordinates[polygon_data_list[polygonID].nodeID]     # polygonの座標\n",
    "    # print(polygon_i.coordinates)\n",
    "\n",
    "    # print(polygon_i.faces)\n",
    "\n",
    "    # polygon_i.faces を取得するコード\n",
    "    \n",
    "    element_to_check = polygon_data_list[polygonID].nodeID[0]\n",
    "    polygon_i.face = mesh.faces[(mesh.faces == element_to_check).any(dim=1)]\n",
    "\n",
    "    indices = torch.nonzero(torch.isin(polygon_i.face, polygon_data_list[polygonID].nodeID))\n",
    "    for idx in range(indices.size(0)):\n",
    "        row_idx, col_idx = indices[idx]\n",
    "        value_to_replace = polygon_i.face[row_idx, col_idx]\n",
    "        polygon_i.face[row_idx, col_idx] = (polygon_data_list[polygonID].nodeID == value_to_replace).nonzero().item()\n",
    "    polygon_i.faces = polygon_i.face.long()\n",
    "\n",
    "    # 各行の三角形からエッジを抽出してedge_indexを構築\n",
    "    edges = torch.cat([ polygon_i.faces[:, [0, 1]],\n",
    "                        polygon_i.faces[:, [1, 2]],\n",
    "                        polygon_i.faces[:, [2, 0]]], dim=0)\n",
    "\n",
    "    # エッジのインデックスをソートして重複を削除\n",
    "    edge_index = torch.sort(edges, dim=1).values\n",
    "    edge_index = torch.tensor(sorted(edge_index.numpy().tolist())).unique(dim=0)\n",
    "    polygon_i.edge_index = torch.transpose(edge_index, 0, 1)\n",
    "    return polygon_i\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メッシュをプロットする関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh(mesh, title):\n",
    "\n",
    "    vertices = mesh.coordinates\n",
    "    faces = mesh.faces\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, aspect=\"equal\")\n",
    "\n",
    "    # 各三角形をプロット\n",
    "    for face in faces:\n",
    "        v0, v1, v2 = vertices[face]\n",
    "        v0_np = v0.detach().numpy()\n",
    "        v1_np = v1.detach().numpy()\n",
    "        v2_np = v2.detach().numpy()\n",
    "        ax.plot([v0_np[0], v1_np[0], v2_np[0], v0_np[0]], [v0_np[1], v1_np[1], v2_np[1], v0_np[1]], 'b-')  # 三角形を赤色の線でプロット\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.001)\n",
    "    ax.axvline(0, color=\"black\", linewidth=0.001)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mesh(mesh, title):\n",
    "\n",
    "    vertices = mesh.coordinates\n",
    "    faces = mesh.faces\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, aspect=\"equal\")\n",
    "\n",
    "\n",
    "    # 各三角形をプロット\n",
    "    for face in faces:\n",
    "        v0, v1, v2 = vertices[face]\n",
    "        v0_np = v0.detach().numpy()\n",
    "        v1_np = v1.detach().numpy()\n",
    "        v2_np = v2.detach().numpy()\n",
    "        ax.plot([v0_np[0], v1_np[0], v2_np[0], v0_np[0]], [v0_np[1], v1_np[1], v2_np[1], v0_np[1]], 'b-')  # 三角形を赤色の線でプロット\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.001)\n",
    "    ax.axvline(0, color=\"black\", linewidth=0.001)\n",
    "\n",
    "    plt.savefig(f\"{fig_save_path}{title}.png\", format=\"png\")\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meshデータからvtkファイルを出力する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vtk_output(mesh, title):\n",
    "    vertices = mesh.coordinates\n",
    "    faces = mesh.faces\n",
    "    num_vertices = len(vertices)\n",
    "    num_faces = len(faces)\n",
    "\n",
    "\n",
    "    # vertices を３次元に戻す\n",
    "    z_column = torch.zeros(vertices.shape[0], 1)\n",
    "    vertices = torch.cat((vertices, z_column), dim=1)\n",
    "\n",
    "    with open(f\"{vtk_save_path}{title}.vtk\", \"w\") as f:\n",
    "        f.write(\"# vtk DataFile Version 2.0\\n\")\n",
    "        f.write(\"FOR TEST\\n\")\n",
    "        f.write(\"ASCII\\n\")\n",
    "        f.write(\"DATASET POLYDATA\\n\")\n",
    "\n",
    "        f.write(\"POINTS {} float\\n\".format(num_vertices))\n",
    "        for vertex in vertices:\n",
    "            f.write(\"{:.15f} {:.15f} {:.15f}\\n\".format(*vertex))\n",
    "\n",
    "        f.write(\"\\nPOLYGONS {} {}\\n\".format(num_faces, num_faces * 4))\n",
    "        for face in faces:\n",
    "            f.write(\"3 \")\n",
    "            f.write(\" \".join(str(idx.item()) for idx in face))\n",
    "            f.write(\"\\n\")\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(polygon):\n",
    "    vertices = polygon.coordinates\n",
    "    normalized_vertices = vertices.clone()\n",
    "    centered_vertices = vertices.clone()\n",
    "\n",
    "    max_x = torch.max(vertices[:,0])\n",
    "    min_x = torch.min(vertices[:,0])\n",
    "    max_y = torch.max(vertices[:,1])\n",
    "    min_y = torch.min(vertices[:,1])\n",
    "\n",
    "    polygon.d = torch.max(max_x - min_x, max_y - min_y)\n",
    "    polygon.x_min = min_x\n",
    "    polygon.y_min = min_y\n",
    "\n",
    "    normalized_vertices = (vertices - torch.tensor([polygon.x_min, polygon.y_min])) / polygon.d\n",
    "\n",
    "    \n",
    "    polygon.Cx = normalized_vertices[0,0].item()\n",
    "    polygon.Cy = normalized_vertices[0,1].item()\n",
    "\n",
    "    centered_vertices = normalized_vertices - torch.tensor([polygon.Cx, polygon.Cy])\n",
    "    polygon.coordinates = centered_vertices\n",
    "    \n",
    "\n",
    "    return polygon\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalization(polygon):\n",
    "    vertices = polygon.coordinates\n",
    "    shifted_vertices = vertices.clone()\n",
    "    denormalized_vertices = vertices.clone()\n",
    "    \n",
    "    shifted_vertices = vertices + torch.tensor([polygon.Cx, polygon.Cy])\n",
    "        \n",
    "    denormalized_vertices = polygon.d * shifted_vertices + torch.tensor([polygon.x_min, polygon.y_min])\n",
    "    polygon.coordinates = denormalized_vertices\n",
    "    return polygon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetricLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ログをファイルに保存するようにしている\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='metric_loss.log',\n",
    "    level=logging.DEBUG, \n",
    "    format='%(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MetricLoss:\n",
    "    def select_vertices(self, vertices, face):\n",
    "        v0 = vertices[face[0]].clone()\n",
    "        v1 = vertices[face[1]].clone()\n",
    "        v2 = vertices[face[2]].clone()\n",
    "        return v0, v1, v2 \n",
    "\n",
    "    def edge_length(self, v0, v1, v2):\n",
    "        l1 = torch.sqrt((v0[0] - v1[0])**2 + (v0[1] - v1[1])**2)\n",
    "        l2 = torch.sqrt((v1[0] - v2[0])**2 + (v1[1] - v2[1])**2)\n",
    "        l3 = torch.sqrt((v2[0] - v0[0])**2 + (v2[1] - v0[1])**2)\n",
    "\n",
    "        return l1, l2, l3\n",
    "\n",
    "    def face_area(self, polygon, l1, l2, l3):   # エラーのときはポリゴンを表示する\n",
    "        \n",
    "        s = 0.5*(l1 + l2 + l3)\n",
    "        temp = s*(s-l1)*(s-l2)*(s-l3)\n",
    "        logger.info(\"    s, in_sqrt: {}, {}\".format(s.item(), temp.item()))\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            face_area = torch.sqrt(temp)\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            SimplePolygonGenerator.polygon_visualizer(polygon)\n",
    "            \n",
    "            print(\"An error occurred\")\n",
    "            print(\"Value of temp:\", temp)\n",
    "            print(l1.item(), l2.item(), l3.item())\n",
    "            \n",
    "            raise\n",
    "        \n",
    "        return face_area\n",
    "\n",
    "    def compute_loss(self, polygon, vertices, face, dx):\n",
    "        v0, v1, v2 = self.select_vertices(vertices, face)\n",
    "        if dx is not None:          # わからんけどどれか原点にあるやつが自由点だからそれを移動させよう\n",
    "            if face[0]==0:\n",
    "                v0 = v0 + dx\n",
    "            elif face[1]==0:\n",
    "                v1 += v1 + dx\n",
    "            elif face[2]==0:\n",
    "                v2 += v2 + dx\n",
    "        #print(v0, v1, v2)\n",
    "        logger.info(\"    v0: ({}, {})\".format(v0[0].item(), v0[1].item()))\n",
    "        logger.info(\"    v1: ({}, {})\".format(v1[0].item(), v1[1].item()))\n",
    "        logger.info(\"    v2: ({}, {})\".format(v2[0].item(), v2[1].item()))\n",
    "        l1, l2, l3 = self.edge_length(v0, v1, v2)\n",
    "        logger.info(\"    l1, l2, l3:  {}, {}, {}\".format(l1.item(), l2.item(), l3.item()))\n",
    "        s = self.face_area(polygon, l1, l2, l3)\n",
    "\n",
    "        loss = 1-(4.0*torch.sqrt(torch.tensor(3.))*s)/(l1**2 + l2**2 + l3**2)\n",
    "        logger.info(\"    area, loss: {}, {}\".format(s.item(), loss.item()))\n",
    "        logger.info(\"\")\n",
    "        \n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def __call__(self, polygon, dx=None):\n",
    "        vertices = polygon.coordinates\n",
    "        faces = polygon.faces\n",
    "        loss = 0 \n",
    "        for face in faces:\n",
    "            loss = loss + self.compute_loss(polygon, vertices, face, dx)\n",
    "        \n",
    "        metric_loss = loss/(len(polygon.coordinates[:,0])-1) \n",
    "        return metric_loss\n",
    "    \n",
    "    \n",
    "def print_grad(grad):\n",
    "    print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meshデータからq_hatを求める関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_q_hat(mesh):\n",
    "    vertices = mesh.coordinates\n",
    "    faces = mesh.faces\n",
    "    r_list = []\n",
    "    alpha_list = []\n",
    "    beta_list = []\n",
    "\n",
    "    for face in faces:\n",
    "        # a(最小角)と b(最大角)を求める\n",
    "\n",
    "        angles = []\n",
    "        v0, v1, v2 = m_loss.select_vertices(vertices, face)\n",
    "        l1, l2, l3 = m_loss.edge_length(v0, v1, v2)\n",
    "\n",
    "        # 余弦定理から各角度の余弦値を計算\n",
    "        cos_alpha = (l2**2 + l3**2 - l1**2) / (2*l2*l3)\n",
    "        cos_beta = (l1**2 + l3**2 - l2**2) / (2*l1*l3)\n",
    "        cos_gamma = (l1**2 + l2**2 - l3**2) / (2*l1*l2)\n",
    "        # 余弦値から角度を計算して個度法に変換\n",
    "        alpha = torch.acos(cos_alpha) * 180 / np.pi\n",
    "        beta = torch.acos(cos_beta) * 180 / np.pi\n",
    "        gamma = torch.acos(cos_gamma) * 180 / np.pi\n",
    "\n",
    "        angles.append(alpha)\n",
    "        angles.append(beta)\n",
    "        angles.append(gamma)\n",
    "\n",
    "        min_angle = min(angles)\n",
    "        max_angle = max(angles)\n",
    "\n",
    "        alpha_list.append(min_angle)\n",
    "        beta_list.append(max_angle)\n",
    "\n",
    "    # 1/q = r を求める\n",
    "    for i in range(len(test_polygonID_list)):\n",
    "        polygonID = i \n",
    "        polygon = data_getter(polygonID, 0, test_mesh_data_lists, test_polygon_data_list)\n",
    "\n",
    "        r = 1 - m_loss(polygon) \n",
    "        r_list.append(r)\n",
    "\n",
    "    a_mean = sum(alpha_list) / len(alpha_list)\n",
    "    a_min = min(alpha_list)\n",
    "    b_mean = sum(beta_list) / len(beta_list)\n",
    "    b_max = max(beta_list)\n",
    "    r_mean = sum(r_list) / len(r_list)\n",
    "    r_min = min(r_list)\n",
    "\n",
    "    q_hat = (((a_mean + a_min + 120 - b_max - b_mean)/60) + r_mean + r_min) / 6\n",
    "\n",
    "    return q_hat\n",
    "\n",
    "    \n",
    "\n",
    "def calculate_qhat(mesh):\n",
    "    vertices = mesh.coordinates\n",
    "    faces = mesh.faces\n",
    "    r_list = []\n",
    "    alpha_list = []\n",
    "    beta_list = []\n",
    "\n",
    "    for face in faces:\n",
    "        # a(最小角)と b(最大角)を求める\n",
    "\n",
    "        angles = []\n",
    "        v0, v1, v2 = m_loss.select_vertices(vertices, face)\n",
    "        l1, l2, l3 = m_loss.edge_length(v0, v1, v2)\n",
    "\n",
    "        # 余弦定理から各角度の余弦値を計算\n",
    "        cos_alpha = (l2**2 + l3**2 - l1**2) / (2*l2*l3)\n",
    "        cos_beta = (l1**2 + l3**2 - l2**2) / (2*l1*l3)\n",
    "        cos_gamma = (l1**2 + l2**2 - l3**2) / (2*l1*l2)\n",
    "        # 余弦値から角度を計算して個度法に変換\n",
    "        alpha = torch.acos(cos_alpha) * 180 / np.pi\n",
    "        beta = torch.acos(cos_beta) * 180 / np.pi\n",
    "        gamma = torch.acos(cos_gamma) * 180 / np.pi\n",
    "\n",
    "        angles.append(alpha)\n",
    "        angles.append(beta)\n",
    "        angles.append(gamma)\n",
    "\n",
    "        min_angle = min(angles)\n",
    "        max_angle = max(angles)\n",
    "\n",
    "        alpha_list.append(min_angle)\n",
    "        beta_list.append(max_angle)\n",
    "\n",
    "        # 1/q = r を求める\n",
    "        v0, v1, v2 = m_loss.select_vertices(vertices, face)\n",
    "        l1, l2, l3 = m_loss.edge_length(v0, v1, v2)\n",
    "        s = 0.5*(l1 + l2 + l3)\n",
    "        temp = s*(s-l1)*(s-l2)*(s-l3)\n",
    "        loss = 1-(4.0*torch.sqrt(torch.tensor(3.))*s)/(l1**2 + l2**2 + l3**2)\n",
    "        r_list.append(1./loss)\n",
    "\n",
    "\n",
    "\n",
    "    a_mean = sum(alpha_list) / len(alpha_list)\n",
    "    a_min = min(alpha_list)\n",
    "    b_mean = sum(beta_list) / len(beta_list)\n",
    "    b_max = max(beta_list)\n",
    "    r_mean = sum(r_list) / len(r_list)\n",
    "    r_min = min(r_list)\n",
    "\n",
    "    q_hat = (((a_mean + a_min + 120 - b_max - b_mean)/60) + r_mean + r_min) / 6\n",
    "\n",
    "    return q_hat\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スターポリゴンの中から外側に自由点が移動したときに自由点の移動量を半分にしてもう一度外に行っていないか検証する\n",
    "自由点が外に行かないことを確認したあとのスターポリゴンを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(polygon, polygonID):\n",
    "    # print(\"polygonID:\", polygonID)\n",
    "    vertices = polygon.coordinates\n",
    "    \n",
    "    edge_index = polygon.edge_index\n",
    "    \n",
    "    return_value = True\n",
    "    while return_value == True:   \n",
    "\n",
    "        for i in range(1, len(vertices[:,0])):\n",
    "            point1 = torch.tensor([0.0, 0.0])\n",
    "            point2 = vertices[0]\n",
    "            point3 = vertices[i]\n",
    "            \n",
    "            pos_i = torch.where(edge_index[0] == i)\n",
    "            pos_i = pos_i[0]\n",
    "            # print(\"edge_index[0]\", edge_index[0])\n",
    "            \n",
    "            for j in range(len(pos_i)):\n",
    "                if edge_index[1, pos_i[j]] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    val_pos_i = edge_index[1, pos_i[j]]\n",
    "                    break\n",
    "\n",
    "            point4 = vertices[val_pos_i]\n",
    "\n",
    "\n",
    "            a1 = 0\n",
    "            b1 = 0\n",
    "            a2 = 0\n",
    "            b2 = 0\n",
    "            check1 = 0\n",
    "            check2 = 0\n",
    "            check3 = 0\n",
    "            check4 = 0\n",
    "            x1 = point1[0]\n",
    "            y1 = point1[1]\n",
    "            x2 = point2[0]\n",
    "            y2 = point2[1]\n",
    "            x3 = point3[0]\n",
    "            y3 = point3[1]\n",
    "            x4 = point4[0]\n",
    "            y4 = point4[1]\n",
    "            a1 = (y1 - y2)/(x1-x2)\n",
    "            b1 = y1 - (a1*x1)\n",
    "            a2 = (y3 - y4)/(x3-x4)\n",
    "            b2 = y3 - (a2*x3)\n",
    "            check1 = (a1*x3) - y3 + b1 \n",
    "            check2 = (a1*x4) - y4 + b1    # point1,2を通る直線に対してpoint3,4を結ぶ線分が交差しているか\n",
    "            check3 = (a2*x1) - y1 + b2\n",
    "            check4 = (a2*x2) - y2 + b2    # point3,4を通る直線に対してpoint1,2を結ぶ線分が交差しているか\n",
    "            # print(\"1:\",check1,\"2:\",check2,\"3:\",check3,\"4:\",check4)\n",
    "            del a1, a2, b1, b2, x1, x2, x3, x4, y1, y2, y3, y4 \n",
    "\n",
    "            if (check1*check2) <= 0 and (check3*check4) <= 0 :\n",
    "                return_value = True\n",
    "                # print(\"Out_of_StarPolygon\")\n",
    "                vertices[0] = 0.5*vertices[0]\n",
    "                polygon.coordinates[0] = vertices[0]\n",
    "                break\n",
    "            else:\n",
    "                return_value = False\n",
    "                continue       \n",
    "            \n",
    "        \n",
    "    # plot_mesh(polygon, \"polygon_checked\")\n",
    "               \n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 隠れ層のノード数は何にするか未定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMSNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, feature_dim, hidden_channnels):   # モデルの初期化\n",
    "        \n",
    "        super(GMSNet, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        self.shared_mlp = Conv1d(input_dim, feature_dim, kernel_size=1) # 1次元の畳み込み層（MLP)入力次元を特徴量次元に変換\n",
    "        self.GNorm = GraphNorm(feature_dim, feature_dim)                # グラフノーマライゼーション層、特徴量の正規化============================================================-\n",
    "        self.conv = GCNConv(feature_dim, feature_dim)                   # グラフ構造を考慮した特徴量抽出を行う\n",
    "        self.fc1 = Linear(feature_dim, hidden_channnels)                # 全結合層 \n",
    "        self.fc2 = Linear(hidden_channnels, input_dim)                  # 全結合層\n",
    "        \n",
    "        self.relu = ReLU()\n",
    "        self.tanh = Tanh()\n",
    "\n",
    "        # Weight initialization\n",
    "        self.apply(self._init_weights)                                  # 重みの初期化\n",
    "\n",
    "    def _init_weights(self, m):     # 線形層と畳み込み層の重みをKaiming正規化で初期化し、バイアスをゼロで初期化する\n",
    "        if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):       \n",
    "        \n",
    "        # feature\n",
    "        x = torch.permute(x, (0, 2, 1))     # polygon.coordinatesを横向きのtensorに変えている\n",
    "        x = self.shared_mlp(x)\n",
    "        feature = self.relu(x)\n",
    "        feature = torch.permute(feature, (0, 2, 1))\n",
    "        \n",
    "        # MLP\n",
    "        target_feature = feature.mean(dim=1)\n",
    "        mlp_midlayer = self.fc1(target_feature)\n",
    "        x = self.relu(mlp_midlayer)\n",
    "        x = self.fc2(x)\n",
    "        x = self.tanh(x)        #出力の値を制限している\n",
    "        \n",
    "        x = 0.1*x\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wing_fine_mesh2']\n"
     ]
    }
   ],
   "source": [
    "# フォルダ内のすべてのvtkファイルにアクセスする\n",
    "test_vtk_files = glob.glob(f\"{test_data_path}*.vtk\")\n",
    "\n",
    "test_vtk_filenames = [file.split('/')[-1].split('.')[0] for file in test_vtk_files]\n",
    "print(test_vtk_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_mesh = len(test_vtk_files)\n",
    "test_mesh_data_list, test_polygonID_list, test_polygon_dict = create_mesh_polygon_dataset(test_vtk_files)\n",
    "\n",
    "test_polygon_data_list = []\n",
    "\n",
    "for i in range(len(test_polygonID_list)):\n",
    "    polygonID = f\"polygon_{i}\"\n",
    "    meshID = test_polygon_dict[f\"polygon_{i}\"][0]\n",
    "    nodeID = test_polygon_dict[f\"polygon_{i}\"][1]\n",
    "    polygon_data = Polygon_data(polygonID, meshID, nodeID)\n",
    "    test_polygon_data_list.append(polygon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_polygonID_list, batch_size=64*num_test_mesh, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "GMSNet(\n",
      "  (shared_mlp): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
      "  (GNorm): GraphNorm(64)\n",
      "  (conv): GCNConv(64, 64)\n",
      "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (tanh): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = GMSNet(input_dim=2, feature_dim=64, hidden_channnels=64)\n",
    "model.to(device)\n",
    "print(model)\n",
    "m_loss = MetricLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "criterion = MetricLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最終的な最適化したメッシュを生成してvtkファイルで出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device, trial):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    temp = 0\n",
    "    ddd = 0\n",
    "\n",
    "    for step, data in enumerate(test_data_loader):\n",
    "        \n",
    "        # optimizer.zero_grad()\n",
    "        metric_loss = 0\n",
    "        dx_list = []\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "\n",
    "            polygonID = int(data[i].split(\"_\")[-1])\n",
    "            polygon = data_getter(polygonID, 0, test_mesh_data_lists[trial], test_polygon_data_list)\n",
    "            polygon = normalization(polygon)              \n",
    "            \n",
    "            x = polygon.coordinates.clone().unsqueeze(0).to(device)\n",
    "            out = model(x)\n",
    "            \n",
    "            logger.info(\"epoch: {:04}, polygonID: {:04}\".format(epoch, polygonID))\n",
    "            logger.info(\"before\")\n",
    "            with torch.no_grad():\n",
    "                ml = criterion(polygon)\n",
    "                logger.info(\"\")\n",
    "            logger.info(\"after\")\n",
    "            l = criterion(polygon, out[0].cpu())\n",
    "            \n",
    "            logger.info(\"\")\n",
    "            \n",
    "            metric_loss += l\n",
    "            dx_list.append(out[0].cpu())\n",
    "            del polygon\n",
    "            \n",
    "        loss = metric_loss/len(data)\n",
    "        ddd += len(data)\n",
    "        temp += loss\n",
    "        # print(\"    Loss:\", loss.item(), \"   Num_step:\", step)      \n",
    "            \n",
    "        for i in range(len(data)):\n",
    "\n",
    "            with torch.no_grad():\n",
    "                polygonID = int(data[i].split(\"_\")[-1])\n",
    "\n",
    "                polygon = data_getter(polygonID, 0, test_mesh_data_lists[trial], test_polygon_data_list)\n",
    "                polygon = normalization(polygon) \n",
    "\n",
    "                polygon.coordinates[0] = polygon.coordinates[0] + dx_list[i]\n",
    "                polygon = denormalization(polygon)\n",
    "                \n",
    "                polygon_meshID = int(test_polygon_data_list[polygonID].meshID.split(\"_\")[-1])\n",
    "                mesh = test_mesh_data_lists[trial][polygon_meshID]\n",
    "                mesh.coordinates[test_polygon_data_list[polygonID].nodeID[0]] = polygon.coordinates[0]\n",
    "                del polygon\n",
    "\n",
    "\n",
    "    test_loss_ave = temp/ddd\n",
    "    writer.add_scalar(\"loss\", test_loss_ave, epoch)       \n",
    "    # print(test_loss_ave, epoch)\n",
    "    loss_list.append(temp/ddd)\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory_profilerをインポート\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage (in MiB): [1277.20703125, 1277.2578125, 1280.59375, 1284.35546875, 1288.27734375, 1291.86328125, 1293.92578125, 1297.58984375, 1301.4375, 1305.140625, 1307.12890625, 1311.08984375, 1314.89453125, 1319.15625, 1321.76171875, 1324.93359375, 1328.91796875, 1332.64453125, 1335.78125, 1335.78125, 1336.6640625, 1339.01953125, 1342.58984375, 1346.3828125, 1350.1875, 1352.30078125, 1356.1328125, 1359.66796875, 1363.48828125, 1365.93359375, 1369.25390625, 1372.98828125, 1376.78515625, 1380.6328125, 1382.73046875, 1386.515625, 1390.328125, 1394.1328125, 1396.01953125, 1399.80078125, 1403.625, 1407.2421875, 1410.2734375, 1413.09765625, 1416.8984375, 1420.75390625, 1424.546875, 1426.3828125, 1430.390625, 1434.1640625, 1438.01171875, 1439.89453125, 1443.76171875, 1447.52734375, 1451.3515625, 1454.67578125, 1457.02734375, 1460.8125, 1464.625, 1468.515625, 1470.3671875, 1474.40234375, 1478.234375, 1481.76953125, 1484.13671875, 1487.6953125, 1491.48828125, 1495.27734375, 1498.6015625, 1500.96875, 1505.046875, 1508.63671875, 1512.703125, 1514.60546875, 1518.44921875, 1522.06640625, 1526.0390625, 1528.234375, 1531.734375, 1535.59765625, 1539.39453125, 1542.73828125, 1545.08203125, 1548.8984375, 1552.7578125, 1556.58203125, 1558.4765625, 1562.2421875, 1566.015625, 1569.86328125, 1572.0390625, 1575.609375, 1579.3984375, 1583.23046875, 1587.0625, 1588.96875, 1593.015625, 1596.78125, 1600.60546875, 1602.515625, 1606.25390625, 1610.12890625, 1613.9296875, 1614.29296875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.05s/it]\n"
     ]
    }
   ],
   "source": [
    "test_mesh_data_lists = [copy.deepcopy(test_mesh_data_list) for _ in range(10)]\n",
    "print(num_trial)\n",
    "loss_list = []\n",
    "trial = 0\n",
    "for trial in tqdm(range(num_trial)):\n",
    "    writer = SummaryWriter(log_dir=\"/mnt/log/test\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"trial{trial}\")\n",
    "    for epoch in range(num_test_epoch):\n",
    "        test(device, trial)\n",
    "        mem_usage = memory_usage((test, (device, trial)), interval=0.1)\n",
    "        print(f\"Memory usage (in MiB): {mem_usage}\")\n",
    "        \n",
    "        for i in range(num_test_mesh):\n",
    "            save_mesh(test_mesh_data_lists[trial][i], f\"{test_vtk_filenames[i]}_trial{trial}_epoch{epoch}\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_mesh_data_list = []\n",
    "# best = []\n",
    "# for i in tqdm(range(num_test_mesh)):\n",
    "#     q_hat_list = []\n",
    "#     for j in range(num_trial):\n",
    "#         mesh = test_mesh_data_lists[j][i]\n",
    "\n",
    "#         q_hat = calculate_qhat(mesh)\n",
    "        \n",
    "#         q_hat_list.append(q_hat)\n",
    "#     print(q_hat_list)\n",
    "#     best.append(q_hat_list.index(min(q_hat_list)))\n",
    "#     print(q_hat_list[best[i]])\n",
    "#     print(\"best_trial:\", best[i])\n",
    "#     best_mesh_data_list.append(test_mesh_data_lists[best[i]][i])\n",
    "\n",
    "#     vtk_output(best_mesh_data_list[i], f\"optimized_{test_vtk_filenames[i]}\")\n",
    "#     plot_mesh(best_mesh_data_list[i], f\"optimized_{test_vtk_filenames[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_gif_from_folder_ascending(folder_path, output_path, filename, trial, duration=1000, loop=0):\n",
    "#     # フォルダ内のすべてのPNGファイルを取得し昇順にソート\n",
    "#     images = []\n",
    "#     file_names = [file_name for file_name in os.listdir(folder_path) if f\"{filename}_trial{trial}\" in file_name and file_name.endswith('.png')]   \n",
    "#     print(file_names)\n",
    "\n",
    "\n",
    "#     file_names.sort(key=lambda x: int(x.split('epoch')[1].split('.')[0]))  # ファイル名の数値部分でソート\n",
    "\n",
    "#     for file_name in file_names:\n",
    "#         file_path = os.path.join(folder_path, file_name)\n",
    "#         images.append(imageio.imread(file_path))\n",
    "    \n",
    "#     # GIFを作成して保存\n",
    "#     imageio.mimsave(output_path, images, duration=duration, loop=loop)\n",
    "\n",
    "\n",
    "# for i in range(num_test_mesh):\n",
    "#     output_path = f'/mnt/gif_folder/{test_vtk_filenames[i]}.gif'    # 出力するGIFファイルのパス\n",
    "#     create_gif_from_folder_ascending(fig_save_path, output_path, test_vtk_filenames[i], best[i], duration=100, loop=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
